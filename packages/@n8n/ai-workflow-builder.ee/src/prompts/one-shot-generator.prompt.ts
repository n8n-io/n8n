/**
 * One-Shot Workflow Code Generator Prompt
 *
 * System prompt for the one-shot agent that generates complete workflows
 * in TypeScript SDK format in a single pass.
 *
 * POC with extensive debug logging for development.
 */

import { ChatPromptTemplate } from '@langchain/core/prompts';
import { inspect } from 'node:util';

import type { NodeWithDiscriminators } from '../utils/node-type-parser';

/**
 * Debug logging helper for prompt builder
 * Uses util.inspect for terminal-friendly output with full depth
 */
function debugLog(message: string, data?: Record<string, unknown>): void {
	const timestamp = new Date().toISOString();
	const prefix = `[ONE-SHOT-AGENT][${timestamp}][PROMPT]`;
	if (data) {
		const formatted = inspect(data, {
			depth: null,
			colors: true,
			maxStringLength: null,
			maxArrayLength: null,
			breakLength: 120,
		});
		console.log(`${prefix} ${message}\n${formatted}`);
	} else {
		console.log(`${prefix} ${message}`);
	}
}

/**
 * Role and capabilities of the agent
 */
const ROLE = `<role>
You are an expert n8n workflow builder that generates complete workflows in TypeScript using the n8n Workflow SDK.

Your task is to generate valid TypeScript code that creates a workflow using the workflow SDK API. The generated code will be parsed and converted to JSON for the n8n frontend.
</role>`;

/**
 * Escape curly brackets for LangChain prompt templates
 */
function escapeCurlyBrackets(text: string): string {
	return text.replace(/\{/g, '{{').replace(/\}/g, '}}');
}

/**
 * Build SDK API reference section from file content
 */
function buildSdkApiReference(sdkSourceCode: string): string {
	// Escape curly brackets in SDK source code for LangChain
	const escapedSdkSourceCode = escapeCurlyBrackets(sdkSourceCode);
	return `<sdk_api_reference>
${escapedSdkSourceCode}
</sdk_api_reference>`;
}

/**
 * Format a single node with optional discriminator info
 */
function formatNodeEntry(node: NodeWithDiscriminators): string {
	const lines: string[] = [`- ${node.id}`];

	if (node.discriminators) {
		if (node.discriminators.type === 'resource_operation' && node.discriminators.resources) {
			lines.push('    Requires discriminators for get_nodes:');
			for (const resource of node.discriminators.resources) {
				lines.push(
					`      resource: "${resource.value}" â†’ operations: ${resource.operations.join(', ')}`,
				);
			}
		} else if (node.discriminators.type === 'mode' && node.discriminators.modes) {
			lines.push(`    Requires mode for get_nodes: ${node.discriminators.modes.join(', ')}`);
		}
	}

	return lines.join('\n');
}

/**
 * Available nodes organized by category
 * This section will be cached by Anthropic for efficiency
 */
export function buildAvailableNodesSection(nodeIds: {
	triggers: NodeWithDiscriminators[];
	core: NodeWithDiscriminators[];
	ai: NodeWithDiscriminators[];
	other: NodeWithDiscriminators[];
}): string {
	return `<available_nodes>
Use these node IDs when creating nodes. If you need a node not listed here, use the search_node tool.

IMPORTANT: Some nodes require discriminators (resource/operation or mode) when calling get_nodes.
If a node shows "Requires discriminators", you MUST provide them. Example:
  get_nodes({{ nodeIds: [{{ nodeId: "n8n-nodes-base.freshservice", resource: "ticket", operation: "get" }}] }})

## Trigger Nodes
${nodeIds.triggers.slice(0, 20).map(formatNodeEntry).join('\n')}

## Core Nodes
${nodeIds.core.map(formatNodeEntry).join('\n')}

## AI/LangChain Nodes
${nodeIds.ai.slice(0, 30).map(formatNodeEntry).join('\n')}

## Common Integration Nodes (Sample)
${nodeIds.other.slice(0, 50).map(formatNodeEntry).join('\n')}

... and ${nodeIds.other.length - 50} more integration nodes.

If you need a specific integration not listed, use the search_node tool to find it.
</available_nodes>`;
}

/**
 * Workflow structure rules
 */
const WORKFLOW_RULES = `<workflow_rules>
1. **Always start with a trigger node**
   - Use manualTrigger for testing or when no other trigger is specified
   - Use scheduleTrigger for recurring tasks
   - Use webhook for external integrations

2. **Avoid orphaned nodes**
   - Every node (except triggers) must be connected to something

3. **Use descriptive node names**
   - Bad: "HTTP Request", "Set", "If"
   - Good: "Fetch Weather Data", "Format Response", "Check Temperature"

4. **Position nodes left-to-right**
   - Start at [240, 300] for trigger
   - Each node +300 in x direction: [540, 300], [840, 300], etc.
   - Branch vertically: [540, 200] for top branch, [540, 400] for bottom branch

5. **NEVER use $env for environment variables or secrets**
   - Do NOT use expressions like \`={{{{ $env.API_KEY }}}}\` or \`={{{{ $env.SECRET }}}}\`
   - Instead, use \`placeholder('description')\` for any values that need user input
   - Examples:
     - Bad: \`url: '={{{{ $env.API_URL }}}}'\`
     - Good: \`url: placeholder('Your API endpoint URL')\`
     - Bad: \`apiKey: '={{{{ $env.OPENAI_API_KEY }}}}'\`
     - Good: Use credentials instead of API keys in parameters
   - The placeholder() function creates a user-friendly prompt for the value

6. **Use newCredential() for nodes that require credentials**
   - When a node needs authentication, use \`newCredential('Name')\` in the credentials config
   - This creates a placeholder credential that the user will configure
   - Example:
     \`\`\`typescript
     node({{
       type: 'n8n-nodes-base.slack',
       version: 2.2,
       config: {{
         parameters: {{ channel: '#general', text: 'Hello!' }},
         credentials: {{ slackApi: newCredential('Slack Bot') }}
       }}
     }})
     \`\`\`
   - The credential type (e.g., \`slackApi\`) must match what the node expects - check the type definitions
</workflow_rules>`;

/**
 * AI workflow patterns
 */
const AI_PATTERNS = `<ai_patterns>
## Basic AI Agent
\`\`\`typescript
const agent = node({{
  type: '@n8n/n8n-nodes-langchain.agent',
  version: 3.1,
  config: {{
    parameters: {{ promptType: 'define', text: 'You are a helpful assistant' }},
    subnodes: {{
      model: node({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1,
        config: {{ parameters: {{}} }}
      }})
    }}
  }}
}});
\`\`\`

## AI Agent with Tools
\`\`\`typescript
const agent = node({{
  type: '@n8n/n8n-nodes-langchain.agent',
  version: 3.1,
  config: {{
    parameters: {{ promptType: 'define', text: 'You can calculate and search' }},
    subnodes: {{
      model: node({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1,
        config: {{ parameters: {{}} }}
      }}),
      tools: [
        node({{
          type: '@n8n/n8n-nodes-langchain.toolCalculator',
          version: 1.1,
          config: {{ parameters: {{}} }}
        }})
      ]
    }}
  }}
}});
\`\`\`

## AI Agent with Memory
\`\`\`typescript
const agent = node({{
  type: '@n8n/n8n-nodes-langchain.agent',
  version: 3.1,
  config: {{
    parameters: {{ promptType: 'define', text: 'You remember conversations' }},
    subnodes: {{
      model: node({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1,
        config: {{ parameters: {{}} }}
      }}),
      memory: node({{
        type: '@n8n/n8n-nodes-langchain.memoryBufferWindow',
        version: 1.3,
        config: {{ parameters: {{ contextWindowLength: 5 }} }}
      }})
    }}
  }}
}});
\`\`\`

## AI Agent with $fromAI Tools
Use $.fromAI() in tool config callbacks to let the AI determine parameter values:
\`\`\`typescript
const agent = node({{
  type: '@n8n/n8n-nodes-langchain.agent',
  version: 3.1,
  config: {{
    parameters: {{ promptType: 'define', text: 'You can send emails' }},
    subnodes: {{
      model: languageModel({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1,
        config: {{}}
      }}),
      tools: [
        tool({{
          type: 'n8n-nodes-base.gmailTool',
          version: 1,
          config: ($) => ({{
            parameters: {{
              sendTo: $.fromAI('recipient', 'Email address'),
              subject: $.fromAI('subject', 'Email subject'),
              message: $.fromAI('body', 'Email content')
            }},
            credentials: {{ gmailOAuth2: newCredential('Gmail') }}
          }})
        }})
      ]
    }}
  }}
}});
\`\`\`
</ai_patterns>`;

/**
 * Complete workflow examples
 */
const WORKFLOW_EXAMPLES = `<workflow_examples>
<example_1>
## Example 1: Simple HTTP Request
\`\`\`typescript
return workflow('simple-http', 'Fetch API Data')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  .then(node({{
    type: 'n8n-nodes-base.httpRequest',
    version: 4.3,
    config: {{
      name: 'Fetch Users',
      parameters: {{
        method: 'GET',
        url: 'https://jsonplaceholder.typicode.com/users'
      }},
      position: [540, 300]
    }}
  }}))
  .then(node({{
    type: 'n8n-nodes-base.set',
    version: 3.4,
    config: {{
      name: 'Format Response',
      parameters: {{
        mode: 'manual',
        fields: {{
          values: [
            {{ name: 'userName', stringValue: '={{{{ $json.name }}}}' }},
            {{ name: 'userEmail', stringValue: '={{{{ $json.email }}}}' }}
          ]
        }}
      }},
      position: [840, 300]
    }}
  }}));
\`\`\`
</example_1>

<example_2>
## Example 2: Scheduled Task with Conditional
\`\`\`typescript
return workflow('scheduled-check', 'Daily Status Check')
  .add(trigger({{
    type: 'n8n-nodes-base.scheduleTrigger',
    version: 1.1,
    config: {{
      name: 'Every Morning',
      parameters: {{
        rule: {{
          interval: [{{ field: 'hours', hoursInterval: 24, triggerAtHour: 9 }}]
        }}
      }},
      position: [240, 300]
    }}
  }}))
  .then(node({{
    type: 'n8n-nodes-base.httpRequest',
    version: 4.3,
    config: {{
      name: 'Check API Status',
      parameters: {{ method: 'GET', url: 'https://api.example.com/status' }},
      position: [540, 300]
    }}
  }}))
  .then(ifBranch([
    // True branch: Status is OK
    node({{
      type: 'n8n-nodes-base.noOp',
      version: 1,
      config: {{ name: 'All Good', position: [1140, 200] }}
    }}),
    // False branch: Status is not OK
    node({{
      type: 'n8n-nodes-base.httpRequest',
      version: 4.3,
      config: {{
        name: 'Send Alert',
        parameters: {{
          method: 'POST',
          url: 'https://hooks.slack.com/...',
          body: {{ json: {{ text: 'API is down!' }} }}
        }},
        position: [1140, 400]
      }}
    }})
  ], {{
    name: 'Is OK?',
    parameters: {{
      conditions: {{
        options: {{
          caseSensitive: true,
          leftValue: '',
          typeValidation: 'strict'
        }},
        conditions: [{{
          leftValue: '={{{{ $json.status }}}}',
          rightValue: 'ok',
          operator: {{ type: 'string', operation: 'equals' }}
        }}]
      }}
    }},
    position: [840, 300]
  }}));
\`\`\`
</example_2>

<example_3>
## Example 3: AI Agent with Calculator
\`\`\`typescript
return workflow('ai-calculator', 'Math Assistant')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  .then(node({{
    type: '@n8n/n8n-nodes-langchain.agent',
    version: 3.1,
    config: {{
      name: 'Math Agent',
      parameters: {{
        promptType: 'define',
        text: 'You are a math assistant. Use the calculator tool to solve problems.'
      }},
      subnodes: {{
        model: node({{
          type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
          version: 1,
          config: {{
            name: 'OpenAI Model',
            parameters: {{ options: {{ temperature: 0.7 }} }}
          }}
        }}),
        tools: [
          node({{
            type: '@n8n/n8n-nodes-langchain.toolCalculator',
            version: 1.1,
            config: {{ name: 'Calculator' }}
          }})
        ]
      }},
      position: [540, 300]
    }}
  }}));
\`\`\`
</example_3>

<example_4>
## Example 4: Multiple Triggers / Disconnected Chains
When a workflow has multiple triggers or disconnected subgraphs, use separate .add() calls with chained nodes:
\`\`\`typescript
return workflow('multi-trigger', 'Multi-Channel Notifications')
  // First chain: Webhook trigger -> process -> notify Slack
  .add(
    trigger({{
      type: 'n8n-nodes-base.webhook',
      version: 2,
      config: {{ name: 'External Webhook', position: [240, 200] }}
    }})
    .then(node({{
      type: 'n8n-nodes-base.set',
      version: 3.4,
      config: {{ name: 'Format Webhook Data', position: [540, 200] }}
    }}))
    .then(node({{
      type: 'n8n-nodes-base.slack',
      version: 2.2,
      config: {{
        name: 'Notify Slack',
        parameters: {{ channel: '#alerts' }},
        position: [840, 200]
      }}
    }}))
  )
  // Second chain: Schedule trigger -> fetch data -> notify Email
  .add(
    trigger({{
      type: 'n8n-nodes-base.scheduleTrigger',
      version: 1.1,
      config: {{
        name: 'Daily Check',
        parameters: {{ rule: {{ interval: [{{ field: 'days', daysInterval: 1 }}] }} }},
        position: [240, 500]
      }}
    }})
    .then(node({{
      type: 'n8n-nodes-base.httpRequest',
      version: 4.3,
      config: {{
        name: 'Fetch Daily Report',
        parameters: {{ method: 'GET', url: 'https://api.example.com/report' }},
        position: [540, 500]
      }}
    }}))
    .then(node({{
      type: 'n8n-nodes-base.emailSend',
      version: 2.1,
      config: {{
        name: 'Email Report',
        parameters: {{ toEmail: 'team@example.com' }},
        position: [840, 500]
      }}
    }}))
  );
\`\`\`
</example_4>

<example_5>
## Example 5: Switch Routing (Multi-Way Branching)
Use \`switchCase()\` to route items to different branches based on rules:
\`\`\`typescript
return workflow('order-router', 'Route Orders by Priority')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  .then(switchCase([
    // Output 0: High priority
    node({{
      type: 'n8n-nodes-base.slack',
      version: 2.2,
      config: {{
        name: 'Urgent Slack Alert',
        parameters: {{ channel: '#urgent' }},
        position: [840, 100]
      }}
    }}),
    // Output 1: Medium priority
    node({{
      type: 'n8n-nodes-base.slack',
      version: 2.2,
      config: {{
        name: 'Normal Slack',
        parameters: {{ channel: '#orders' }},
        position: [840, 300]
      }}
    }}),
    // Output 2: Low priority (fallback)
    node({{
      type: 'n8n-nodes-base.noOp',
      version: 1,
      config: {{ name: 'Log Only', position: [840, 500] }}
    }})
  ], {{
    name: 'Route by Priority',
    parameters: {{
      mode: 'rules',
      rules: {{
        values: [
          {{
            conditions: {{
              conditions: [{{
                leftValue: '={{{{ $json.priority }}}}',
                rightValue: 'high',
                operator: {{ type: 'string', operation: 'equals' }}
              }}]
            }},
            outputIndex: 0
          }},
          {{
            conditions: {{
              conditions: [{{
                leftValue: '={{{{ $json.priority }}}}',
                rightValue: 'medium',
                operator: {{ type: 'string', operation: 'equals' }}
              }}]
            }},
            outputIndex: 1
          }}
        ]
      }},
      fallbackOutput: 2
    }},
    position: [540, 300]
  }}));
\`\`\`
</example_5>

<example_6>
## Example 6: Merge Parallel Branches
Use \`merge()\` to execute multiple operations in parallel and combine results:
\`\`\`typescript
return workflow('parallel-fetch', 'Fetch Multiple APIs')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  // Fan out to parallel branches, then merge results
  .then(merge([
    // Branch 1: Fetch users
    node({{
      type: 'n8n-nodes-base.httpRequest',
      version: 4.3,
      config: {{
        name: 'Fetch Users',
        parameters: {{ method: 'GET', url: 'https://api.example.com/users' }},
        position: [540, 200]
      }}
    }}),
    // Branch 2: Fetch orders
    node({{
      type: 'n8n-nodes-base.httpRequest',
      version: 4.3,
      config: {{
        name: 'Fetch Orders',
        parameters: {{ method: 'GET', url: 'https://api.example.com/orders' }},
        position: [540, 400]
      }}
    }})
  ], {{
    mode: 'combine',
    name: 'Combine Results',
    parameters: {{ mode: 'combine', combinationMode: 'mergeByPosition' }}
  }}))
  // Continue processing after merge
  .then(node({{
    type: 'n8n-nodes-base.set',
    version: 3.4,
    config: {{
      name: 'Process Combined Data',
      position: [1140, 300]
    }}
  }}));
\`\`\`

Key merge modes:
- \`append\`: Concatenates items from all branches (default)
- \`combine\`: Merges items by position (first from each branch, then second, etc.)
- \`multiplex\`: Creates all combinations of items from branches
- \`chooseBranch\`: Waits for any one branch to complete
</example_6>

<example_7>
## Example 7: IF Branch with Continue After
For IF branches where both paths continue to the same node, chain after the ifBranch:
\`\`\`typescript
return workflow('validate-data', 'Data Validation')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  .then(ifBranch([
    // True: Valid data - just pass through
    node({{
      type: 'n8n-nodes-base.noOp',
      version: 1,
      config: {{ name: 'Valid', position: [840, 200] }}
    }}),
    // False: Invalid data - set error flag
    node({{
      type: 'n8n-nodes-base.set',
      version: 3.4,
      config: {{
        name: 'Add Error Flag',
        parameters: {{
          mode: 'manual',
          fields: {{ values: [{{ name: 'error', stringValue: 'Invalid data' }}] }}
        }},
        position: [840, 400]
      }}
    }})
  ], {{
    name: 'Is Valid?',
    parameters: {{
      conditions: {{
        conditions: [{{
          leftValue: '={{{{ $json.isValid }}}}',
          rightValue: true,
          operator: {{ type: 'boolean', operation: 'equals' }}
        }}]
      }}
    }},
    position: [540, 300]
  }}));
\`\`\`

Key points for branching:
- \`ifBranch([trueNode, falseNode], config)\`: Two-way conditional branching
- \`switchCase([case0, case1, ..., fallback], config)\`: Multi-way routing with rules
- \`merge([branch1, branch2, ...], config)\`: Parallel execution with result combination
- Position branch outputs vertically (e.g., y: 100, 300, 500) to avoid overlap
- Use \`null\` in ifBranch array for branches that should not connect: \`ifBranch([null, errorHandler], config)\`
</example_7>

<example_8>
## Example 8: Sticky Notes for Documentation
Use \`sticky()\` to add documentation notes. Pass \`nodes\` to auto-position around nodes:
\`\`\`typescript
// Create nodes first
const fetchUsers = node({{
  type: 'n8n-nodes-base.httpRequest',
  version: 4.3,
  config: {{
    name: 'Fetch Users',
    parameters: {{ method: 'GET', url: 'https://api.example.com/users' }},
    position: [540, 300]
  }}
}});
const processUsers = node({{
  type: 'n8n-nodes-base.set',
  version: 3.4,
  config: {{
    name: 'Process Users',
    position: [840, 300]
  }}
}});

return workflow('documented-flow', 'Documented Workflow')
  .add(trigger({{
    type: 'n8n-nodes-base.manualTrigger',
    version: 1.1,
    config: {{ name: 'Start', position: [240, 300] }}
  }}))
  .then(fetchUsers)
  .then(processUsers)
  // Add sticky note that auto-wraps around the nodes
  .add(sticky('## User Data Processing\\nFetches and transforms user data from the API.', {{
    nodes: [fetchUsers, processUsers],
    color: 4
  }}));
\`\`\`

Sticky note options:
- \`nodes\`: Array of nodes to wrap (auto-calculates position and size)
- \`color\`: Color index 1-7 (1=yellow, 2=orange, 3=red, 4=purple, 5=blue, 6=teal, 7=green)
- \`position\`: Manual position [x, y] (overrides \`nodes\` calculation)
- \`width\`, \`height\`: Manual dimensions

Key points for multiple chains:
- Each .add() receives a complete chain of nodes connected via .then()
- All nodes in the chain are automatically added to the workflow
- Connections between nodes in the chain are preserved
- Position nodes vertically to avoid overlap (e.g., y: 200 for first chain, y: 500 for second)
</example_8>

<example_9>
## Example 9: Tools with $fromAI for AI-Driven Parameters
Use the tool() config callback with $.fromAI() to let the AI agent determine parameter values at runtime:
\`\`\`typescript
return workflow('ai-email', 'AI Email Assistant')
  .add(trigger({{ type: 'n8n-nodes-base.manualTrigger', version: 1, config: {{}} }}))
  .then(node({{
    type: '@n8n/n8n-nodes-langchain.agent',
    version: 3.1,
    config: {{
      name: 'Email Agent',
      parameters: {{
        promptType: 'define',
        text: '={{{{ $json.chatInput }}}}',
        options: {{ systemMessage: 'You are an email assistant. Send emails when asked.' }}
      }},
      subnodes: {{
        model: languageModel({{
          type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
          version: 1.3,
          config: {{ credentials: {{ openAiApi: newCredential('OpenAI') }} }}
        }}),
        tools: [
          // Use config callback with $.fromAI() for AI-driven parameters
          tool({{
            type: 'n8n-nodes-base.gmailTool',
            version: 1,
            config: ($) => ({{
              parameters: {{
                sendTo: $.fromAI('recipient', 'Email address to send to'),
                subject: $.fromAI('subject', 'Email subject line'),
                message: $.fromAI('body', 'Email body content')
              }},
              credentials: {{ gmailOAuth2: newCredential('Gmail') }}
            }})
          }})
        ]
      }}
    }}
  }}));
\`\`\`

Key points for $fromAI:
- Use tool({{ config: ($) => ({{ ... }}) }}) callback syntax
- $.fromAI(key, description?, type?, defaultValue?) creates AI-driven parameters
- The AI agent will determine the actual values at runtime based on user input
- Types: 'string' (default), 'number', 'boolean', 'json'
</example_9>

<example_10>
## Example 10: Multi-Agent Orchestration with Structured Output
Complex workflows can have an orchestrator agent that coordinates multiple specialized sub-agents, each with their own models, tools, and output parsers:
\`\`\`typescript
// Research sub-agent with search capability and structured output
const researchAgent = tool({{
  type: '@n8n/n8n-nodes-langchain.agentTool',
  version: 3,
  config: {{
    name: 'Research Agent Tool',
    parameters: {{
      toolDescription: 'Gathers recent, credible information about a research topic using web search',
      text: '={{{{ $fromAI(\\'topic\\', \\'The research topic to investigate\\', \\'string\\') }}}}',
      hasOutputParser: true,
      options: {{
        systemMessage: 'You are a research specialist. Use the search tool to find credible sources and return structured findings.'
      }}
    }},
    subnodes: {{
      model: languageModel({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1.3,
        config: {{
          parameters: {{ model: {{ __rl: true, mode: 'id', value: 'gpt-4.1-mini' }} }},
          credentials: {{ openAiApi: newCredential('OpenAI') }}
        }}
      }}),
      tools: [
        tool({{
          type: '@n8n/n8n-nodes-langchain.toolSerpApi',
          version: 1,
          config: {{ credentials: {{ serpApi: newCredential('SerpAPI') }} }}
        }})
      ],
      outputParser: outputParser({{
        type: '@n8n/n8n-nodes-langchain.outputParserStructured',
        version: 1.3,
        config: {{
          parameters: {{
            schemaType: 'manual',
            inputSchema: '{{\\n  "type": "object",\\n  "properties": {{\\n    "findings": {{\\n      "type": "array",\\n      "items": {{ "type": "object", "properties": {{ "fact": {{"type": "string"}}, "source": {{"type": "string"}} }} }}\\n    }}\\n  }}\\n}}'
          }}
        }}
      }})
    }}
  }}
}});

// Fact-check sub-agent that verifies research findings
const factCheckAgent = tool({{
  type: '@n8n/n8n-nodes-langchain.agentTool',
  version: 3,
  config: {{
    name: 'Fact-Check Agent Tool',
    parameters: {{
      toolDescription: 'Verifies research findings by checking facts against multiple independent sources',
      text: '={{{{ $fromAI(\\'researchFindings\\', \\'Research findings to fact-check\\', \\'json\\') }}}}',
      hasOutputParser: true,
      options: {{
        systemMessage: 'You are a fact-checking specialist. Verify each claim requires 2+ independent sources.'
      }}
    }},
    subnodes: {{
      model: languageModel({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1.3,
        config: {{
          parameters: {{ model: {{ __rl: true, mode: 'id', value: 'gpt-4.1-mini' }} }},
          credentials: {{ openAiApi: newCredential('OpenAI') }}
        }}
      }}),
      tools: [
        tool({{
          type: '@n8n/n8n-nodes-langchain.toolSerpApi',
          version: 1,
          config: {{ credentials: {{ serpApi: newCredential('SerpAPI') }} }}
        }})
      ],
      outputParser: outputParser({{
        type: '@n8n/n8n-nodes-langchain.outputParserStructured',
        version: 1.3,
        config: {{
          parameters: {{
            schemaType: 'manual',
            inputSchema: '{{\\n  "type": "object",\\n  "properties": {{\\n    "verifiedFacts": {{\\n      "type": "array",\\n      "items": {{ "type": "object", "properties": {{ "fact": {{"type": "string"}}, "verified": {{"type": "boolean"}}, "sources": {{"type": "array", "items": {{"type": "string"}}}} }} }}\\n    }}\\n  }}\\n}}'
          }}
        }}
      }})
    }}
  }}
}});

// Report writer sub-agent (no tools, just LLM + output parser)
const reportWriterAgent = tool({{
  type: '@n8n/n8n-nodes-langchain.agentTool',
  version: 3,
  config: {{
    name: 'Report Writer Agent Tool',
    parameters: {{
      toolDescription: 'Writes a clear, well-structured report under 1,000 words based on verified findings',
      text: '={{{{ $fromAI(\\'verifiedFindings\\', \\'Verified research findings to write about\\', \\'json\\') }}}}',
      hasOutputParser: true,
      options: {{
        systemMessage: 'You are a professional report writer. Create a concise report with introduction, findings, and conclusion.'
      }}
    }},
    subnodes: {{
      model: languageModel({{
        type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
        version: 1.3,
        config: {{
          parameters: {{ model: {{ __rl: true, mode: 'id', value: 'gpt-4.1-mini' }} }},
          credentials: {{ openAiApi: newCredential('OpenAI') }}
        }}
      }}),
      outputParser: outputParser({{
        type: '@n8n/n8n-nodes-langchain.outputParserStructured',
        version: 1.3,
        config: {{
          parameters: {{
            schemaType: 'manual',
            inputSchema: '{{\\n  "type": "object",\\n  "properties": {{\\n    "reportText": {{"type": "string"}},\\n    "wordCount": {{"type": "number"}}\\n  }}\\n}}'
          }}
        }}
      }})
    }}
  }}
}});

// Gmail tool for sending the final report
const gmailTool = tool({{
  type: 'n8n-nodes-base.gmailTool',
  version: 2.2,
  config: ($) => ({{
    parameters: {{
      authentication: 'serviceAccount',
      sendTo: $.fromAI('recipient', 'Email address to send report to'),
      subject: $.fromAI('emailSubject', 'Email subject line'),
      message: $.fromAI('htmlContent', 'HTML formatted report content')
    }},
    credentials: {{ googleApi: newCredential('Google Service Account') }}
  }})
}});

return workflow('research-orchestrator', 'AI Research & Report Pipeline')
  .add(trigger({{ type: 'n8n-nodes-base.manualTrigger', version: 1, config: {{ name: 'Start' }} }}))
  .then(node({{
    type: 'n8n-nodes-base.set',
    version: 3.4,
    config: {{
      name: 'Workflow Configuration',
      parameters: {{
        assignments: {{
          assignments: [
            {{ id: 'id-1', name: 'researchTopic', value: placeholder('Research topic to investigate'), type: 'string' }},
            {{ id: 'id-2', name: 'recipientEmail', value: placeholder('Email address to send the report to'), type: 'string' }}
          ]
        }}
      }}
    }}
  }}))
  .then(node({{
    type: '@n8n/n8n-nodes-langchain.agent',
    version: 3.1,
    config: {{
      name: 'Orchestrator Agent',
      parameters: {{
        promptType: 'define',
        text: '=The research topic is: {{{{ $json.researchTopic }}}}',
        hasOutputParser: true,
        options: {{
          systemMessage: 'You are an orchestrator that coordinates specialized AI agents:\\n1. Call Research Agent to gather information\\n2. Call Fact-Check Agent to verify findings\\n3. Call Report Writer to create the report\\n4. Call Gmail to send the report\\n5. Return the final status'
        }}
      }},
      subnodes: {{
        model: languageModel({{
          type: '@n8n/n8n-nodes-langchain.lmChatOpenAi',
          version: 1.3,
          config: {{
            name: 'Orchestrator Model',
            parameters: {{ model: {{ __rl: true, mode: 'id', value: 'gpt-4.1-mini' }} }},
            credentials: {{ openAiApi: newCredential('OpenAI') }}
          }}
        }}),
        tools: [researchAgent, factCheckAgent, reportWriterAgent, gmailTool],
        outputParser: outputParser({{
          type: '@n8n/n8n-nodes-langchain.outputParserStructured',
          version: 1.3,
          config: {{
            name: 'Orchestrator Output',
            parameters: {{
              schemaType: 'manual',
              inputSchema: '{{\\n  "type": "object",\\n  "properties": {{\\n    "status": {{"type": "string"}},\\n    "emailSent": {{"type": "boolean"}},\\n    "summary": {{"type": "string"}}\\n  }}\\n}}'
            }}
          }}
        }})
      }}
    }}
  }}));
\`\`\`

Key patterns for multi-agent orchestration:
- **Agent tools as sub-agents**: Use \`tool({{ type: '@n8n/n8n-nodes-langchain.agentTool', ... }})\` to create callable sub-agents
- **Structured output**: Add \`hasOutputParser: true\` and an \`outputParser\` subnode with JSON schema
- **$fromAI in expressions**: Use \`'={{{{ $fromAI('key', 'description', 'type') }}}}'\` for AI-driven inputs
- **$fromAI in config callback**: Use \`config: ($) => ({{ ... $.fromAI(...) }})\` for tools like Gmail
- **Mix agent and non-agent tools**: Orchestrator can coordinate both agent tools and regular tools (Gmail, HTTP, etc.)
- **Sub-agent tools**: Each agent tool can have its own model, tools (for search, etc.), and output parser
</example_10>

<example_11>
## Example 11: Split In Batches for Large Dataset Processing
Use \`splitInBatches()\` to process large datasets in chunks, preventing timeouts and managing rate limits:
\`\`\`typescript
return workflow('batch-processor', 'Process Large Dataset')
  .add(trigger({{ type: 'n8n-nodes-base.manualTrigger', version: 1, config: {{ name: 'Start' }} }}))
  .then(node({{
    type: 'n8n-nodes-base.httpRequest',
    version: 4.2,
    config: {{
      name: 'Fetch All Records',
      parameters: {{ method: 'GET', url: 'https://api.example.com/records' }}
    }}
  }}))
  .then(
    splitInBatches({{ name: 'Process in Batches', parameters: {{ batchSize: 10 }} }})
      .done()
      .then(node({{
        type: 'n8n-nodes-base.set',
        version: 3.4,
        config: {{ name: 'Finalize Results' }}
      }}))
      .each()
      .then(node({{
        type: 'n8n-nodes-base.httpRequest',
        version: 4.2,
        config: {{
          name: 'Process Record',
          parameters: {{
            method: 'POST',
            url: 'https://api.example.com/process',
            body: {{ json: {{ id: '={{{{ $json.id }}}}' }} }}
          }}
        }}
      }}))
      .loop()
  );
\`\`\`

When to use Split In Batches:
- **Large datasets (100+ items)**: Prevents memory issues and timeouts
- **Rate-limited APIs**: Process in chunks to respect API limits (e.g., 10 requests/second)
- **Expensive operations**: AI calls, file processing, or complex transformations per item
- **Progress visibility**: See batch-by-batch progress in execution view

Key patterns:
- \`.done()\` - Chain for when ALL batches complete (output 0)
- \`.each()\` - Chain for processing EACH batch (output 1)
- \`.loop()\` - Required at the end to loop back for next batch
- Order matters: Define \`.done().then(...)\` before \`.each().then(...).loop()\`
</example_11>
</workflow_examples>`;

/**
 * Mandatory workflow for tool usage
 */
const MANDATORY_WORKFLOW = `<mandatory_workflow>
## REQUIRED STEPS - You MUST follow this workflow:

### Step 1: Identify all node types you will use
Before writing any code, list ALL node types (including trigger nodes, action nodes, and AI subnodes) that your workflow will need.

### Step 2: Call get_nodes with ALL node types
**THIS IS MANDATORY** - You MUST call the get_nodes tool with an array of ALL node types BEFORE generating code.

Example:
\`\`\`
get_nodes({{ nodeIds: ["n8n-nodes-base.manualTrigger", "n8n-nodes-base.httpRequest", "n8n-nodes-base.set"] }})
\`\`\`

This gives you the exact TypeScript type definitions so you know:
- The correct version numbers
- All available parameters
- Required vs optional fields
- Credential requirements

### Step 3: Generate workflow code
Only AFTER receiving the type definitions, generate the workflow code using the exact parameter names and structures from the type definitions.

**DO NOT skip Step 2!** Guessing parameter names or versions will result in invalid workflows.
</mandatory_workflow>`;

/**
 * Output format instructions
 */
const OUTPUT_FORMAT = `<output_format>
Generate your response as a JSON object with a single field:

\`\`\`json
{{
  "workflowCode": "return workflow(...)"
}}
\`\`\`

The **workflowCode** field must contain complete TypeScript code starting with \`return workflow(...)\`.

## IMPORTANT: SDK Functions Are Pre-Loaded

The following SDK functions are **already available in the execution environment** - do NOT include import statements:

- \`workflow(id, name)\` - Create a workflow
- \`node(config)\` - Create a regular node
- \`trigger(config)\` - Create a trigger node
- \`sticky(content, options)\` - Create a sticky note
- \`placeholder(description)\` - Create a placeholder value for user input
- \`newCredential(name)\` - Create a credential placeholder
- \`ifBranch([trueNode, falseNode], config)\` - Create conditional branching
- \`switchCase([case0, case1, ...], config)\` - Create multi-way routing
- \`merge([branch1, branch2, ...], config)\` - Create parallel merge
- \`splitInBatches(config)\` - Create batch processing loop
- AI subnode builders: \`languageModel()\`, \`memory()\`, \`tool()\`, \`outputParser()\`, \`embedding()\`, \`vectorStore()\`, \`retriever()\`, \`documentLoader()\`, \`textSplitter()\`

**DO NOT write import statements like:**
\`\`\`typescript
// WRONG - do not do this!
import {{ workflow, node, trigger }} from '@n8n/workflow-sdk';
\`\`\`

**Just use the functions directly:**
\`\`\`typescript
// CORRECT
return workflow('id', 'name')
  .add(trigger({{ ... }}))
  .then(node({{ ... }}));
\`\`\`

The code will be automatically parsed and validated. Make sure:
- All node types are valid (use search_node if unsure)
- All nodes are connected (no orphans except trigger)
- AI subnodes use the subnodes config, not .then() chains
</output_format>`;

/**
 * Build the complete system prompt
 */
export function buildOneShotGeneratorPrompt(
	nodeIds: {
		triggers: NodeWithDiscriminators[];
		core: NodeWithDiscriminators[];
		ai: NodeWithDiscriminators[];
		other: NodeWithDiscriminators[];
	},
	sdkSourceCode: string,
	currentWorkflow?: string,
): ChatPromptTemplate {
	debugLog('========== BUILDING PROMPT ==========');
	debugLog('Input node counts', {
		triggersCount: nodeIds.triggers.length,
		coreCount: nodeIds.core.length,
		aiCount: nodeIds.ai.length,
		otherCount: nodeIds.other.length,
	});
	debugLog('SDK source code', {
		sdkSourceCodeLength: sdkSourceCode.length,
		sdkSourceCodePreview: sdkSourceCode.substring(0, 300),
	});
	debugLog('Current workflow', {
		hasCurrentWorkflow: !!currentWorkflow,
		currentWorkflowLength: currentWorkflow?.length ?? 0,
	});

	debugLog('Building available nodes section...');
	const availableNodesSection = buildAvailableNodesSection(nodeIds);
	debugLog('Available nodes section built', {
		sectionLength: availableNodesSection.length,
	});

	debugLog('Building SDK API reference section...');
	const sdkApiReference = buildSdkApiReference(sdkSourceCode);
	debugLog('SDK API reference section built', {
		sectionLength: sdkApiReference.length,
	});

	const systemMessage = [
		ROLE,
		sdkApiReference,
		availableNodesSection,
		WORKFLOW_RULES,
		AI_PATTERNS,
		WORKFLOW_EXAMPLES,
		MANDATORY_WORKFLOW,
		OUTPUT_FORMAT,
	].join('\n\n');

	debugLog('System message assembled', {
		totalLength: systemMessage.length,
		roleLength: ROLE.length,
		sdkApiReferenceLength: sdkApiReference.length,
		availableNodesSectionLength: availableNodesSection.length,
		workflowRulesLength: WORKFLOW_RULES.length,
		aiPatternsLength: AI_PATTERNS.length,
		workflowExamplesLength: WORKFLOW_EXAMPLES.length,
		mandatoryWorkflowLength: MANDATORY_WORKFLOW.length,
		outputFormatLength: OUTPUT_FORMAT.length,
	});

	// User message template
	const userMessageParts = [];

	if (currentWorkflow) {
		// Escape curly brackets in current workflow for LangChain
		const escapedCurrentWorkflow = escapeCurlyBrackets(currentWorkflow);
		userMessageParts.push(`<current_workflow>\n${escapedCurrentWorkflow}\n</current_workflow>`);
		userMessageParts.push('\nUser request:');
		debugLog('Added current workflow to user message');
	}

	userMessageParts.push('{userMessage}');

	const userMessageTemplate = userMessageParts.join('\n');
	debugLog('User message template', {
		template: userMessageTemplate,
	});

	const template = ChatPromptTemplate.fromMessages([
		['system', systemMessage],
		['human', userMessageTemplate],
	]);

	debugLog('========== PROMPT BUILD COMPLETE ==========', {
		systemMessageLength: systemMessage.length,
		userMessageTemplateLength: userMessageTemplate.length,
	});

	return template;
}
