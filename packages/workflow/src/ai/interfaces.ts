/**
 * n8n AI Abstraction Layer - Core Interfaces
 *
 * These interfaces provide a framework-agnostic way to build AI nodes.
 * Community developers can implement these interfaces using any AI SDK
 * (Anthropic, OpenAI, Cohere, etc.) without depending on LangChain.
 */

import type { IDataObject } from '../interfaces';

/**
 * Message roles in AI conversations
 */
export enum N8nAiMessageRole {
	Human = 'human',
	AI = 'ai',
	System = 'system',
	Function = 'function',
	Tool = 'tool',
}

/**
 * Represents a single message in an AI conversation
 */
export interface IN8nAiMessage {
	/** Role of the message sender */
	role: N8nAiMessageRole;
	/** Content of the message */
	content: string;
	/** Optional metadata attached to the message */
	metadata?: IDataObject;
	/** Optional name/identifier for the message sender */
	name?: string;
	/** Additional message-specific data */
	additional_kwargs?: IDataObject;
}

/**
 * Configuration options for chat models
 */
export interface IN8nChatModelConfig {
	/** Temperature (randomness) for generation, typically 0-1 */
	temperature?: number;
	/** Maximum number of tokens to generate */
	maxTokens?: number;
	/** Top-p sampling parameter */
	topP?: number;
	/** Whether to enable streaming responses */
	streaming?: boolean;
	/** Stop sequences */
	stop?: string[];
	/** Additional provider-specific options */
	[key: string]: unknown;
}

/**
 * Chat Model Interface
 *
 * Implement this interface to create a custom chat model node.
 * The model should be able to generate responses to a series of messages.
 *
 * @example
 * ```typescript
 * class MyCustomChatModel implements IN8nChatModel {
 *   modelName = 'my-model-v1';
 *
 *   async invoke(messages: IN8nAiMessage[]): Promise<IN8nAiMessage> {
 *     // Call your AI provider API
 *     const response = await myAiProvider.chat(messages);
 *     return {
 *       role: N8nAiMessageRole.AI,
 *       content: response.text,
 *     };
 *   }
 * }
 * ```
 */
export interface IN8nChatModel {
	/** Model identifier (e.g., 'gpt-4', 'claude-3-opus') */
	modelName: string;

	/**
	 * Generate a response to a series of messages
	 * @param messages - Conversation history
	 * @returns AI-generated response message
	 */
	invoke(messages: IN8nAiMessage[]): Promise<IN8nAiMessage>;

	/**
	 * Stream a response to a series of messages (optional)
	 * @param messages - Conversation history
	 * @returns Async iterable of response chunks
	 */
	stream?(messages: IN8nAiMessage[]): AsyncIterable<IN8nAiMessage>;

	/**
	 * Invoke with a single prompt string (convenience method)
	 * @param prompt - Single string prompt
	 * @returns AI-generated response message
	 */
	invokeWithPrompt?(prompt: string): Promise<IN8nAiMessage>;

	/** Model configuration options */
	config?: IN8nChatModelConfig;
}

/**
 * Embeddings Interface
 *
 * Implement this interface to create a custom embeddings node.
 * Embeddings convert text into vector representations for similarity search.
 *
 * @example
 * ```typescript
 * class MyCustomEmbeddings implements IN8nEmbeddings {
 *   modelName = 'my-embeddings-v1';
 *
 *   async embedQuery(text: string): Promise<number[]> {
 *     const response = await myAiProvider.embed(text);
 *     return response.vector;
 *   }
 *
 *   async embedDocuments(texts: string[]): Promise<number[][]> {
 *     return await Promise.all(texts.map(t => this.embedQuery(t)));
 *   }
 * }
 * ```
 */
export interface IN8nEmbeddings {
	/**
	 * Generate embedding for a single query text
	 * @param text - Text to embed
	 * @returns Vector embedding (array of numbers)
	 */
	embedQuery(text: string): Promise<number[]>;

	/**
	 * Generate embeddings for multiple documents
	 * @param texts - Array of texts to embed
	 * @returns Array of vector embeddings
	 */
	embedDocuments(texts: string[]): Promise<number[][]>;

	/** Model identifier (optional) */
	modelName?: string;

	/** Dimension of the embedding vectors (optional) */
	dimensions?: number;
}

/**
 * Represents a document with content and metadata
 */
export interface IN8nDocument {
	/** Main content of the document */
	content: string;
	/** Associated metadata (tags, source, timestamps, etc.) */
	metadata?: IDataObject;
	/** Unique identifier (optional, may be generated by vector store) */
	id?: string;
	/** Pre-computed embedding vector (optional) */
	embedding?: number[];
}

/**
 * Search result with similarity score
 */
export interface IN8nDocumentWithScore extends IN8nDocument {
	/** Similarity score (typically 0-1, higher is more similar) */
	score: number;
}

/**
 * Configuration for vector store initialization
 */
export interface IN8nVectorStoreConfig {
	/** Embeddings model to use for vectorization */
	embeddings: IN8nEmbeddings;
	/** Additional provider-specific configuration */
	[key: string]: unknown;
}

/**
 * Vector Store Interface
 *
 * Implement this interface to create a custom vector store node.
 * Vector stores enable semantic search over document collections.
 *
 * @example
 * ```typescript
 * class MyCustomVectorStore implements IN8nVectorStore {
 *   readonly storeType = 'my-vectordb';
 *
 *   async addDocuments(documents: IN8nDocument[]): Promise<string[]> {
 *     // Embed documents and store in database
 *     const embeddings = await this.embeddings.embedDocuments(
 *       documents.map(d => d.content)
 *     );
 *     const ids = await this.db.insert(documents, embeddings);
 *     return ids;
 *   }
 *
 *   async similaritySearch(query: string, k: number): Promise<IN8nDocument[]> {
 *     const queryEmbedding = await this.embeddings.embedQuery(query);
 *     return await this.db.search(queryEmbedding, k);
 *   }
 * }
 * ```
 */
export interface IN8nVectorStore {
	/**
	 * Add documents to the vector store
	 * @param documents - Documents to add
	 * @returns Array of document IDs
	 */
	addDocuments(documents: IN8nDocument[]): Promise<string[]>;

	/**
	 * Search for documents similar to a query
	 * @param query - Search query text
	 * @param k - Number of results to return (default: 4)
	 * @param filter - Optional metadata filter
	 * @returns Array of similar documents
	 */
	similaritySearch(query: string, k?: number, filter?: IDataObject): Promise<IN8nDocument[]>;

	/**
	 * Search for documents with similarity scores
	 * @param query - Search query text
	 * @param k - Number of results to return (default: 4)
	 * @param filter - Optional metadata filter
	 * @returns Array of documents with scores
	 */
	similaritySearchWithScore?(
		query: string,
		k?: number,
		filter?: IDataObject,
	): Promise<IN8nDocumentWithScore[]>;

	/**
	 * Delete documents by ID
	 * @param ids - Array of document IDs to delete
	 */
	delete?(ids: string[]): Promise<void>;

	/**
	 * Type identifier for this vector store
	 * (e.g., 'pinecone', 'qdrant', 'weaviate')
	 */
	readonly storeType: string;
}

/**
 * Parameter definition for AI tools
 */
export interface IN8nToolParameter {
	/** Parameter name */
	name: string;
	/** Parameter type */
	type: 'string' | 'number' | 'boolean' | 'object' | 'array';
	/** Human-readable description of the parameter */
	description: string;
	/** Whether this parameter is required */
	required?: boolean;
	/** Default value if not provided */
	default?: unknown;
	/** Enum of allowed values (optional) */
	enum?: unknown[];
}

/**
 * Schema defining tool parameters
 */
export interface IN8nToolSchema {
	/** Array of parameter definitions */
	parameters: IN8nToolParameter[];
}

/**
 * Tool Interface
 *
 * Implement this interface to create a custom tool for AI agents.
 * Tools allow AI models to perform actions and retrieve information.
 *
 * @example
 * ```typescript
 * class MyCustomTool implements IN8nTool {
 *   name = 'search_products';
 *   description = 'Search for products in the database';
 *
 *   schema = {
 *     parameters: [
 *       {
 *         name: 'query',
 *         type: 'string',
 *         description: 'Search query',
 *         required: true,
 *       },
 *       {
 *         name: 'limit',
 *         type: 'number',
 *         description: 'Maximum results',
 *         default: 10,
 *       },
 *     ],
 *   };
 *
 *   async call(input: IDataObject): Promise<string> {
 *     const results = await this.db.search(input.query, input.limit);
 *     return JSON.stringify(results);
 *   }
 * }
 * ```
 */
export interface IN8nTool {
	/** Tool name (should be descriptive and snake_case) */
	name: string;

	/** Description of what the tool does (for AI to understand) */
	description: string;

	/** Parameter schema defining inputs */
	schema: IN8nToolSchema;

	/**
	 * Execute the tool with given input
	 * @param input - Tool input parameters
	 * @returns Tool result as a string (JSON stringify if needed)
	 */
	call(input: IDataObject): Promise<string>;

	/**
	 * Whether the tool returns data directly to the user (optional)
	 * If true, the tool's output is sent as the final response
	 */
	returnsDirect?: boolean;
}

/**
 * Memory Interface
 *
 * Implement this interface to create a custom memory/history store.
 * Memory allows AI agents to maintain conversation context.
 *
 * @example
 * ```typescript
 * class MyCustomMemory implements IN8nMemory {
 *   private history: IN8nAiMessage[] = [];
 *
 *   async loadMemory(): Promise<IN8nAiMessage[]> {
 *     return [...this.history];
 *   }
 *
 *   async saveContext(input: string, output: string): Promise<void> {
 *     this.history.push(
 *       { role: N8nAiMessageRole.Human, content: input },
 *       { role: N8nAiMessageRole.AI, content: output }
 *     );
 *   }
 *
 *   async clear(): Promise<void> {
 *     this.history = [];
 *   }
 * }
 * ```
 */
export interface IN8nMemory {
	/**
	 * Load conversation history
	 * @returns Array of historical messages
	 */
	loadMemory(): Promise<IN8nAiMessage[]>;

	/**
	 * Save a conversation turn (input + output)
	 * @param input - User input
	 * @param output - AI output
	 */
	saveContext(input: string, output: string): Promise<void>;

	/**
	 * Clear all conversation history
	 */
	clear(): Promise<void>;

	/**
	 * Get memory as variables for prompt injection (optional)
	 * @returns Object with memory variables
	 */
	loadMemoryVariables?(): Promise<IDataObject>;
}

/**
 * Output Parser Interface
 *
 * Implement this interface to create a custom output parser.
 * Parsers extract structured data from AI model outputs.
 *
 * @example
 * ```typescript
 * class MyCustomParser implements IN8nOutputParser<{ name: string; age: number }> {
 *   async parse(text: string): Promise<{ name: string; age: number }> {
 *     // Parse text to extract structured data
 *     const match = text.match(/Name: (.*), Age: (\d+)/);
 *     if (!match) throw new Error('Failed to parse');
 *     return { name: match[1], age: parseInt(match[2]) };
 *   }
 *
 *   getFormatInstructions(): string {
 *     return 'Format your response as: Name: [name], Age: [age]';
 *   }
 * }
 * ```
 */
export interface IN8nOutputParser<T = unknown> {
	/**
	 * Parse text output into structured data
	 * @param text - Raw text from AI model
	 * @returns Parsed structured data
	 */
	parse(text: string): Promise<T>;

	/**
	 * Get instructions for the AI on how to format its output
	 * @returns Format instructions string to add to prompt
	 */
	getFormatInstructions(): string;
}

/**
 * AI Node Type Identifiers
 *
 * Used for type checking and routing in n8n workflows
 */
export enum N8nAiNodeType {
	LanguageModel = 'languageModel',
	ChatModel = 'chatModel',
	Embeddings = 'embeddings',
	VectorStore = 'vectorStore',
	Tool = 'tool',
	Memory = 'memory',
	OutputParser = 'outputParser',
}
