{
	"httpRequest": {
		"method": "POST",
		"path": "/v1/messages"
	},
	"httpResponse": {
		"statusCode": 200,
		"reasonPhrase": "OK",
		"headers": {
			"x-envoy-upstream-service-time": ["5015"],
			"strict-transport-security": ["max-age=31536000; includeSubDomains; preload"],
			"retry-after": ["19"],
			"request-id": ["req_011CUfbJ6pXNj9J6GoNNvPGU"],
			"cf-cache-status": ["DYNAMIC"],
			"anthropic-ratelimit-tokens-reset": ["2025-10-31T16:28:42Z"],
			"anthropic-ratelimit-tokens-remaining": ["15500000"],
			"anthropic-ratelimit-tokens-limit": ["15500000"],
			"anthropic-ratelimit-output-tokens-reset": ["2025-10-31T16:28:44Z"],
			"anthropic-ratelimit-output-tokens-remaining": ["500000"],
			"anthropic-ratelimit-output-tokens-limit": ["500000"],
			"anthropic-ratelimit-input-tokens-reset": ["2025-10-31T16:28:42Z"],
			"anthropic-ratelimit-input-tokens-remaining": ["15000000"],
			"anthropic-ratelimit-input-tokens-limit": ["15000000"],
			"X-Robots-Tag": ["none"],
			"Server": ["cloudflare"],
			"Date": ["Fri, 31 Oct 2025 16:28:44 GMT"],
			"Content-Type": ["application/json"],
			"CF-RAY": ["997486dccde6f469-MAN"]
		},
		"body": {
			"contentType": "application/json",
			"type": "JSON",
			"json": {
				"model": "claude-sonnet-4-5-20250929",
				"id": "msg_01TCQAdZAWre5GHXSCobMxx3",
				"type": "message",
				"role": "assistant",
				"content": [
					{
						"type": "tool_use",
						"id": "toolu_018fLJaxzXmoEUEwW8GNqLih",
						"name": "add_nodes",
						"input": {
							"nodeType": "@n8n/n8n-nodes-langchain.chainLlm",
							"name": "Generate Chapters with AI",
							"connectionParametersReasoning": "Basic LLM Chain has dynamic inputs based on hasOutputParser parameter. Since we don't need output parser for this use case, setting hasOutputParser to false to only accept main input and language model connection.",
							"connectionParameters": {
								"hasOutputParser": false
							},
							"id": "12143dd5-e8ae-4837-8775-547521b10f7b"
						}
					}
				],
				"stop_reason": "tool_use",
				"stop_sequence": null,
				"usage": {
					"input_tokens": 1,
					"cache_creation_input_tokens": 1500,
					"cache_read_input_tokens": 33126,
					"cache_creation": {
						"ephemeral_5m_input_tokens": 1500,
						"ephemeral_1h_input_tokens": 0
					},
					"output_tokens": 178,
					"service_tier": "standard"
				}
			},
			"rawBytes": "eyJtb2RlbCI6ImNsYXVkZS1zb25uZXQtNC01LTIwMjUwOTI5IiwiaWQiOiJtc2dfMDFUQ1FBZFpBV3JlNUdIWFNDb2JNeHgzIiwidHlwZSI6Im1lc3NhZ2UiLCJyb2xlIjoiYXNzaXN0YW50IiwiY29udGVudCI6W3sidHlwZSI6InRvb2xfdXNlIiwiaWQiOiJ0b29sdV8wMThmTEpheHpYbW9FVUV3VzhHTnFMaWgiLCJuYW1lIjoiYWRkX25vZGVzIiwiaW5wdXQiOnsibm9kZVR5cGUiOiJAbjhuL244bi1ub2Rlcy1sYW5nY2hhaW4uY2hhaW5MbG0iLCJuYW1lIjoiR2VuZXJhdGUgQ2hhcHRlcnMgd2l0aCBBSSIsImNvbm5lY3Rpb25QYXJhbWV0ZXJzUmVhc29uaW5nIjoiQmFzaWMgTExNIENoYWluIGhhcyBkeW5hbWljIGlucHV0cyBiYXNlZCBvbiBoYXNPdXRwdXRQYXJzZXIgcGFyYW1ldGVyLiBTaW5jZSB3ZSBkb24ndCBuZWVkIG91dHB1dCBwYXJzZXIgZm9yIHRoaXMgdXNlIGNhc2UsIHNldHRpbmcgaGFzT3V0cHV0UGFyc2VyIHRvIGZhbHNlIHRvIG9ubHkgYWNjZXB0IG1haW4gaW5wdXQgYW5kIGxhbmd1YWdlIG1vZGVsIGNvbm5lY3Rpb24uIiwiY29ubmVjdGlvblBhcmFtZXRlcnMiOnsiaGFzT3V0cHV0UGFyc2VyIjpmYWxzZX19fV0sInN0b3BfcmVhc29uIjoidG9vbF91c2UiLCJzdG9wX3NlcXVlbmNlIjpudWxsLCJ1c2FnZSI6eyJpbnB1dF90b2tlbnMiOjEsImNhY2hlX2NyZWF0aW9uX2lucHV0X3Rva2VucyI6MTUwMCwiY2FjaGVfcmVhZF9pbnB1dF90b2tlbnMiOjMzMTI2LCJjYWNoZV9jcmVhdGlvbiI6eyJlcGhlbWVyYWxfNW1faW5wdXRfdG9rZW5zIjoxNTAwLCJlcGhlbWVyYWxfMWhfaW5wdXRfdG9rZW5zIjowfSwib3V0cHV0X3Rva2VucyI6MTc4LCJzZXJ2aWNlX3RpZXIiOiJzdGFuZGFyZCJ9fQ=="
		}
	},
	"id": "1761928197575-unknown-host-POST-_v1_messages-ae7f9640.json",
	"priority": 15,
	"timeToLive": {
		"unlimited": true
	},
	"times": {
		"remainingTimes": 1,
		"unlimited": false
	}
}
